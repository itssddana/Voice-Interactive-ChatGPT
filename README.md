
# Voice-Interactive ChatGPT

## Introduction

The **Voice-Interactive ChatGPT** project enables users to interact with OpenAI's GPT models using voice input. This integration allows the user to speak their queries, receive answers from ChatGPT, and listen to the responses in audio format. The project uses several Python libraries for speech recognition, text generation, and text-to-speech conversion to provide a seamless voice interaction experience.

## Project Description

This project was created to make ChatGPT accessible through voice, providing an intuitive user interface for users who prefer voice interactions rather than typing. The application leverages:
1. **Speech Recognition**: To convert spoken input into text.
2. **ChatGPT API**: To generate intelligent responses based on the input text.
3. **Text-to-Speech (TTS)**: To convert the ChatGPT response back into audible speech.

The core components of the system are:
- **Voice Input**: Captures user’s voice using the microphone.
- **Speech to Text**: Converts the recorded voice into a text query.
- **ChatGPT API**: Sends the query to OpenAI’s GPT model and retrieves a response.
- **Text to Speech**: Converts the text response into speech and plays it back to the user.

## How It Was Done

### Step 1: Recording the Voice
The first step in the process was to capture the user’s voice. I used the **`speech_recognition`** library in Python to record audio from the microphone.

- **Libraries Used**: `speech_recognition`
- **Code Example**:
  
    import speech_recognition as sr

    def record_audio():
        recognizer = sr.Recognizer()
        microphone = sr.Microphone()

        with microphone as source:
            print("Please speak now...")
            recognizer.adjust_for_ambient_noise(source)
            audio = recognizer.listen(source)

        return audio
    د

### Step 2: Converting Audio to Text
After recording the voice, I converted the audio to text using the Google Web Speech API from the `speech_recognition` library. This allowed the system to understand the spoken words and transform them into a format that can be sent to the ChatGPT API.

- **Libraries Used**: `speech_recognition`
- **Code Example**:
    def audio_to_text(audio):
        recognizer = sr.Recognizer()
        try:
            print("Processing audio...")
            text = recognizer.recognize_google(audio)
            print("You said:", text)
            return text
        except sr.UnknownValueError:
            print("Could not understand the audio.")
            return None
        except sr.RequestError:
            print("Could not request results.")
            return None

### Step 3: Sending Text to ChatGPT
The text received from the speech-to-text conversion is then sent to the ChatGPT API using OpenAI's Python library. This API generates a response based on the input query.

- **Libraries Used**: `openai`
- **Code Example**:
    import openai

    openai.api_key = 'your-api-key'

    def get_chatgpt_response(text):
        response = openai.Completion.create(
            engine="gpt-4",  # or "gpt-3.5-turbo" for chat models
            prompt=text,
            max_tokens=150
        )
        return response.choices[0].text.strip()
    

### Step 4: Converting Text to Speech
Finally, the response generated by ChatGPT is converted back into speech using the **gTTS (Google Text-to-Speech)** library. The resulting audio is saved and played for the user.

- **Libraries Used**: `gtts`
- **Code Example**:
    from gtts import gTTS
    import os

    def text_to_audio(response_text):
        tts = gTTS(text=response_text, lang='en')
        tts.save("response.mp3")
        os.system("start response.mp3")  # For Windows, use 'open' on macOS or 'mpg321' on Linux
    

### Step 5: Putting It All Together
The final step involved integrating all the components: recording the audio, converting it to text, sending it to ChatGPT, and converting the response back to speech. The user can interact with the system by simply speaking and listening to the responses.



## What I Learned
Through building this project, I learned how to:
1. **Integrate APIs**: I gained experience in integrating third-party APIs such as OpenAI's GPT-3 and speech recognition libraries.
2. **Voice Interaction**: I learned how to handle voice input and output in Python, which is useful for building voice-controlled applications.
3. **Handling Audio**: Converting between speech and text can be tricky, especially when handling noise or unclear speech, but using libraries like `speech_recognition` made this much easier.
4. **Python Libraries**: I explored useful Python libraries like `openai`, `speech_recognition`, and `gTTS` for building real-time voice-interactive systems.


## Helpful Resources

Here are some useful resources that helped during the development of this project:

1. **Speech Recognition Library (Python)**:
   - [Official Documentation for `speech_recognition`](https://pypi.org/project/SpeechRecognition/)
   - This library allowed me to capture audio and convert it to text using various APIs.
   
2. **OpenAI API**:
   - [Official OpenAI API Documentation](https://beta.openai.com/docs/)
   - This documentation helped me set up and use OpenAI's GPT models to generate responses from text inputs.

3. **gTTS (Google Text-to-Speech)**:
   - [gTTS Documentation](https://gtts.readthedocs.io/en/latest/)
   - This library allowed me to convert text responses back into speech that could be played back to the user.

4. **Python `pygame` Library** (optional for audio playback):
   - [pygame Documentation](https://www.pygame.org/docs/)
   - If you want to enhance audio control, `pygame` is an excellent library to consider for playing the generated speech.


## Conclusion

In this project, I successfully built a system that integrates speech recognition and OpenAI's GPT model to provide voice-based interactions with ChatGPT. By leveraging Python libraries, I was able to make the process of interacting with ChatGPT more accessible for users who prefer speaking over typing.
